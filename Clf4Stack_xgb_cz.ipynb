{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Feature Engineering (Obtained before hand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def FeatureEngineering(trainpath,testpath):\n",
    "    #### Load Data\n",
    "    train = pd.read_csv(trainpath)\n",
    "    test = pd.read_csv(testpath)\n",
    "\n",
    "    ### \n",
    "    y = train['target'].values\n",
    "    testid= test['id'].values\n",
    "    \n",
    "    ### Drop calc\n",
    "    unwanted = train.columns[train.columns.str.startswith('ps_calc_')]\n",
    "    train = train.drop(unwanted, axis=1)  \n",
    "    test = test.drop(unwanted, axis=1)\n",
    "\n",
    "    train.drop(['id','target'],axis=1,inplace=True)\n",
    "    test.drop(['id'],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "    \n",
    "    trainX = np.array(train)\n",
    "    testX = np.array(test)\n",
    "    trainy = np.array(y)\n",
    "    \n",
    "    return trainX, trainy, testX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gini(actual, pred, cmpcol = 0, sortcol = 1):\n",
    "    assert( len(actual) == len(pred) )\n",
    "    all = np.asarray(np.c_[ actual, pred, np.arange(len(actual)) ], dtype=np.float)\n",
    "    all = all[ np.lexsort((all[:,2], -1*all[:,1])) ]\n",
    "    totalLosses = all[:,0].sum()\n",
    "    giniSum = all[:,0].cumsum().sum() / totalLosses\n",
    " \n",
    "    giniSum -= (len(actual) + 1) / 2.\n",
    "    return giniSum / len(actual)\n",
    " \n",
    "def gini_normalized(a, p):\n",
    "    return gini(a, p) / gini(a, a)\n",
    "\n",
    "def gini_coefficient(preds,dtrain):\n",
    "    y = dtrain.get_label()\n",
    "    return 'gini', -gini_normalized(y,preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Class for stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "class Clf4Stack_xgb(object):\n",
    "    def __init__(self, model, metric, early_stopping_rounds=100, test_size=0.25, verbose=False, n_splits=5):\n",
    "        self.n_splits = n_splits\n",
    "        self.model = model\n",
    "        self.metric = metric\n",
    "        self.early_stopping_rounds = early_stopping_rounds\n",
    "        self.test_size = test_size\n",
    "        self.verbose = verbose\n",
    "        \n",
    "\n",
    "    def fit_predict(self, trainX, trainy, testX):\n",
    "\n",
    "        self.train4stack = np.zeros(len(trainX))\n",
    "        self.test4stack = np.zeros(len(testX))\n",
    "\n",
    "        skf = StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=0)\n",
    "\n",
    "        for i, (train_index,test_index) in enumerate(skf.split(trainX, trainy)):\n",
    "            print(\"=====Round {0}/{1}=====\".format(i+1,self.n_splits))\n",
    "            X_train, X_test = trainX[train_index], trainX[test_index]\n",
    "            y_train, y_test = trainy[train_index], trainy[test_index]\n",
    "\n",
    "            x1, x2, y1, y2 = train_test_split(X_train, y_train, test_size=self.test_size, random_state=99)\n",
    "            \n",
    "            self.model.fit(x1, y1, \n",
    "                           eval_set=[(x1,y1),(x2,y2)], \n",
    "                           eval_metric=self.metric,\n",
    "                           early_stopping_rounds=self.early_stopping_rounds,\n",
    "                           verbose=self.verbose)            \n",
    "            \n",
    "            y_pred = self.model.predict_proba(X_test,ntree_limit=self.model.best_ntree_limit+50)[:,1]\n",
    "            self.train4stack[test_index] = y_pred\n",
    "            self.test4stack += self.model.predict_proba(testX,ntree_limit=self.model.best_ntree_limit+50)[:,1]\n",
    "        \n",
    "        self.test4stack /= self.n_splits\n",
    "            \n",
    "    def output(self,train_file_name='train4stack.csv',\n",
    "                    test_file_name='test4stack.csv',\n",
    "                    col_name='F4stack'):\n",
    "\n",
    "        pd.DataFrame({col_name:self.train4stack}).to_csv(train_file_name,index=False) \n",
    "        pd.DataFrame({col_name:self.test4stack}).to_csv(test_file_name,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainpath = \"train.csv\"\n",
    "testpath = \"test.csv\"\n",
    "\n",
    "trainX, trainy, testX = FeatureEngineering(trainpath,testpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Build Model (the optimal hyperparameters obtained before hand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=0.7, colsample_bytree=0.9,\n",
       "       gamma=0, learning_rate=0.02, max_delta_step=0, max_depth=4,\n",
       "       min_child_weight=100, missing=None, n_estimators=2000, nthread=-1,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=99, silent=True, subsample=0.9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "params = {'learning_rate': 0.02, \n",
    "          'n_estimators': 2000,\n",
    "          'max_depth': 4, \n",
    "          'subsample': 0.9,\n",
    "          'colsample_bytree': 0.9, \n",
    "          'colsample_bylevel':0.7,\n",
    "          'min_child_weight':100,\n",
    "          'objective': 'binary:logistic', \n",
    "          'seed': 99, \n",
    "          'silent': True}\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "xgb.set_params(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Generate data for stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "C4S = Clf4Stack_xgb(xgb, \n",
    "                    gini_coefficient, \n",
    "                    early_stopping_rounds=100, \n",
    "                    test_size=0.25, \n",
    "                    verbose=100, \n",
    "                    n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Round 1/5=====\n",
      "[0]\tvalidation_0-gini:-0.200038\tvalidation_1-gini:-0.179792\n",
      "Multiple eval metrics have been passed: 'validation_1-gini' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-gini hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-gini:-0.257237\tvalidation_1-gini:-0.234429\n",
      "[200]\tvalidation_0-gini:-0.277127\tvalidation_1-gini:-0.249765\n",
      "[300]\tvalidation_0-gini:-0.295401\tvalidation_1-gini:-0.261181\n",
      "[400]\tvalidation_0-gini:-0.306533\tvalidation_1-gini:-0.267397\n",
      "[500]\tvalidation_0-gini:-0.315217\tvalidation_1-gini:-0.27096\n",
      "[600]\tvalidation_0-gini:-0.322254\tvalidation_1-gini:-0.273083\n",
      "[700]\tvalidation_0-gini:-0.328146\tvalidation_1-gini:-0.274274\n",
      "[800]\tvalidation_0-gini:-0.333728\tvalidation_1-gini:-0.275217\n",
      "[900]\tvalidation_0-gini:-0.338815\tvalidation_1-gini:-0.275758\n",
      "[1000]\tvalidation_0-gini:-0.343453\tvalidation_1-gini:-0.276294\n",
      "[1100]\tvalidation_0-gini:-0.348444\tvalidation_1-gini:-0.276361\n",
      "Stopping. Best iteration:\n",
      "[1040]\tvalidation_0-gini:-0.345522\tvalidation_1-gini:-0.276505\n",
      "\n",
      "=====Round 2/5=====\n",
      "[0]\tvalidation_0-gini:-0.196965\tvalidation_1-gini:-0.195323\n",
      "Multiple eval metrics have been passed: 'validation_1-gini' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-gini hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-gini:-0.25379\tvalidation_1-gini:-0.241276\n",
      "[200]\tvalidation_0-gini:-0.27575\tvalidation_1-gini:-0.26067\n",
      "[300]\tvalidation_0-gini:-0.294916\tvalidation_1-gini:-0.272833\n",
      "[400]\tvalidation_0-gini:-0.306352\tvalidation_1-gini:-0.2775\n",
      "[500]\tvalidation_0-gini:-0.315345\tvalidation_1-gini:-0.280504\n",
      "[600]\tvalidation_0-gini:-0.322336\tvalidation_1-gini:-0.282305\n",
      "[700]\tvalidation_0-gini:-0.328977\tvalidation_1-gini:-0.284127\n",
      "[800]\tvalidation_0-gini:-0.334177\tvalidation_1-gini:-0.28471\n",
      "[900]\tvalidation_0-gini:-0.339477\tvalidation_1-gini:-0.284934\n",
      "[1000]\tvalidation_0-gini:-0.344283\tvalidation_1-gini:-0.285299\n",
      "[1100]\tvalidation_0-gini:-0.349021\tvalidation_1-gini:-0.285691\n",
      "Stopping. Best iteration:\n",
      "[1099]\tvalidation_0-gini:-0.348913\tvalidation_1-gini:-0.285695\n",
      "\n",
      "=====Round 3/5=====\n",
      "[0]\tvalidation_0-gini:-0.197667\tvalidation_1-gini:-0.192163\n",
      "Multiple eval metrics have been passed: 'validation_1-gini' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-gini hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-gini:-0.256747\tvalidation_1-gini:-0.239906\n",
      "[200]\tvalidation_0-gini:-0.278068\tvalidation_1-gini:-0.25581\n",
      "[300]\tvalidation_0-gini:-0.296537\tvalidation_1-gini:-0.268789\n",
      "[400]\tvalidation_0-gini:-0.308178\tvalidation_1-gini:-0.274712\n",
      "[500]\tvalidation_0-gini:-0.317265\tvalidation_1-gini:-0.278787\n",
      "[600]\tvalidation_0-gini:-0.325362\tvalidation_1-gini:-0.281032\n",
      "[700]\tvalidation_0-gini:-0.331283\tvalidation_1-gini:-0.281592\n",
      "[800]\tvalidation_0-gini:-0.337096\tvalidation_1-gini:-0.282523\n",
      "[900]\tvalidation_0-gini:-0.341796\tvalidation_1-gini:-0.282884\n",
      "[1000]\tvalidation_0-gini:-0.34672\tvalidation_1-gini:-0.283356\n",
      "[1100]\tvalidation_0-gini:-0.350938\tvalidation_1-gini:-0.283496\n",
      "[1200]\tvalidation_0-gini:-0.355706\tvalidation_1-gini:-0.283413\n",
      "Stopping. Best iteration:\n",
      "[1124]\tvalidation_0-gini:-0.352093\tvalidation_1-gini:-0.283571\n",
      "\n",
      "=====Round 4/5=====\n",
      "[0]\tvalidation_0-gini:-0.189576\tvalidation_1-gini:-0.177091\n",
      "Multiple eval metrics have been passed: 'validation_1-gini' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-gini hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-gini:-0.253335\tvalidation_1-gini:-0.244369\n",
      "[200]\tvalidation_0-gini:-0.275815\tvalidation_1-gini:-0.261259\n",
      "[300]\tvalidation_0-gini:-0.295174\tvalidation_1-gini:-0.270403\n",
      "[400]\tvalidation_0-gini:-0.306767\tvalidation_1-gini:-0.275483\n",
      "[500]\tvalidation_0-gini:-0.316387\tvalidation_1-gini:-0.279199\n",
      "[600]\tvalidation_0-gini:-0.324548\tvalidation_1-gini:-0.281876\n",
      "[700]\tvalidation_0-gini:-0.330564\tvalidation_1-gini:-0.282961\n",
      "[800]\tvalidation_0-gini:-0.335979\tvalidation_1-gini:-0.28405\n",
      "[900]\tvalidation_0-gini:-0.34092\tvalidation_1-gini:-0.284749\n",
      "[1000]\tvalidation_0-gini:-0.346233\tvalidation_1-gini:-0.284714\n",
      "Stopping. Best iteration:\n",
      "[956]\tvalidation_0-gini:-0.343981\tvalidation_1-gini:-0.285031\n",
      "\n",
      "=====Round 5/5=====\n",
      "[0]\tvalidation_0-gini:-0.183672\tvalidation_1-gini:-0.16324\n",
      "Multiple eval metrics have been passed: 'validation_1-gini' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-gini hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-gini:-0.254304\tvalidation_1-gini:-0.247199\n",
      "[200]\tvalidation_0-gini:-0.275911\tvalidation_1-gini:-0.266217\n",
      "[300]\tvalidation_0-gini:-0.293524\tvalidation_1-gini:-0.278221\n",
      "[400]\tvalidation_0-gini:-0.305277\tvalidation_1-gini:-0.285475\n",
      "[500]\tvalidation_0-gini:-0.314697\tvalidation_1-gini:-0.290446\n",
      "[600]\tvalidation_0-gini:-0.321908\tvalidation_1-gini:-0.293153\n",
      "[700]\tvalidation_0-gini:-0.328654\tvalidation_1-gini:-0.295132\n",
      "[800]\tvalidation_0-gini:-0.334908\tvalidation_1-gini:-0.296181\n",
      "[900]\tvalidation_0-gini:-0.340604\tvalidation_1-gini:-0.297041\n",
      "[1000]\tvalidation_0-gini:-0.345812\tvalidation_1-gini:-0.297312\n",
      "[1100]\tvalidation_0-gini:-0.350701\tvalidation_1-gini:-0.297805\n",
      "[1200]\tvalidation_0-gini:-0.35525\tvalidation_1-gini:-0.29752\n",
      "Stopping. Best iteration:\n",
      "[1140]\tvalidation_0-gini:-0.352621\tvalidation_1-gini:-0.297925\n",
      "\n",
      "Wall time: 25min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "C4S.fit_predict(trainX, trainy, testX)\n",
    "\n",
    "C4S.output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
