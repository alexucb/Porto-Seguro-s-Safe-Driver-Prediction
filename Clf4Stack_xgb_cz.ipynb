{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Feature Engineering (Obtained before hand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def FeatureEngineering(trainpath,testpath):\n",
    "    #### Load Data\n",
    "    train = pd.read_csv(trainpath)\n",
    "    test = pd.read_csv(testpath)\n",
    "\n",
    "    ### \n",
    "    y = train['target'].values\n",
    "    testid= test['id'].values\n",
    "    \n",
    "    ### Drop calc\n",
    "    unwanted = train.columns[train.columns.str.startswith('ps_calc_')]\n",
    "    train = train.drop(unwanted, axis=1)  \n",
    "    test = test.drop(unwanted, axis=1)\n",
    "\n",
    "    train.drop(['id','target'],axis=1,inplace=True)\n",
    "    test.drop(['id'],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "    \n",
    "    trainX = np.array(train)\n",
    "    testX = np.array(test)\n",
    "    trainy = np.array(y)\n",
    "    \n",
    "    return trainX, trainy, testX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gini(actual, pred, cmpcol = 0, sortcol = 1):\n",
    "    assert( len(actual) == len(pred) )\n",
    "    all = np.asarray(np.c_[ actual, pred, np.arange(len(actual)) ], dtype=np.float)\n",
    "    all = all[ np.lexsort((all[:,2], -1*all[:,1])) ]\n",
    "    totalLosses = all[:,0].sum()\n",
    "    giniSum = all[:,0].cumsum().sum() / totalLosses\n",
    " \n",
    "    giniSum -= (len(actual) + 1) / 2.\n",
    "    return giniSum / len(actual)\n",
    " \n",
    "def gini_normalized(a, p):\n",
    "    return gini(a, p) / gini(a, a)\n",
    "\n",
    "def gini_coefficient(preds,dtrain):\n",
    "    y = dtrain.get_label()\n",
    "    return 'gini', -gini_normalized(y,preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Class for stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "class Clf4Stack_xgb(object):\n",
    "    def __init__(self, model, metric, nrounds, early_stopping_rounds=100, test_size=0.25, verbose=False, n_splits=5):\n",
    "        self.n_splits = n_splits\n",
    "        self.model = model\n",
    "        self.metric = metric\n",
    "        self.nrounds = nrounds\n",
    "        self.early_stopping_rounds = early_stopping_rounds\n",
    "        self.test_size = test_size\n",
    "        self.verbose = verbose\n",
    "        \n",
    "\n",
    "    def fit_predict(self, trainX, trainy, testX):\n",
    "\n",
    "        self.train4stack = np.zeros(len(trainX))\n",
    "        self.test4stack = np.zeros(len(testX))\n",
    "\n",
    "        skf = StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=44)\n",
    "\n",
    "        for i, (train_index,test_index) in enumerate(skf.split(trainX, trainy)):\n",
    "            print(\"=====Round {0}/{1}=====\".format(i+1,self.n_splits))\n",
    "            X_train, X_test = trainX[train_index], trainX[test_index]\n",
    "            y_train, y_test = trainy[train_index], trainy[test_index]\n",
    "\n",
    "            x1, x2, y1, y2 = train_test_split(X_train, y_train, test_size=self.test_size, random_state=99)\n",
    "            \n",
    "            nrounds=2000\n",
    "            d_train = xgb.DMatrix(X_train, y_train) \n",
    "            d_valid = xgb.DMatrix(X_test, y_test) \n",
    "            watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "            xgb_model = xgb.train(params, d_train, nrounds, watchlist, early_stopping_rounds=100, \n",
    "                                  feval=gini_coefficient, maximize=True, verbose_eval=100)\n",
    "            #sub['target'] += xgb_model.predict(xgb.DMatrix(test[features].values),\n",
    "            # ntree_limit=xgb_model.best_ntree_limit+50) / (2*kfold)\n",
    "            \n",
    "            y_pred = self.model.predict_proba(X_test,ntree_limit=self.model.best_ntree_limit+50)[:,1]\n",
    "            self.train4stack[test_index] = y_pred\n",
    "            self.test4stack += self.model.predict_proba(testX,ntree_limit=self.model.best_ntree_limit+50)[:,1]\n",
    "        \n",
    "        self.test4stack /= self.n_splits\n",
    "            \n",
    "    def output(self,train_file_name='train4stack.csv',\n",
    "                    test_file_name='test4stack.csv',\n",
    "                    col_name='F4stack'):\n",
    "\n",
    "        pd.DataFrame({col_name:self.train4stack}).to_csv(train_file_name,index=False) \n",
    "        pd.DataFrame({col_name:self.test4stack}).to_csv(test_file_name,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainpath = \"train.csv\"\n",
    "testpath = \"test.csv\"\n",
    "\n",
    "trainX, trainy, testX = FeatureEngineering(trainpath,testpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Build Model (the optimal hyperparameters obtained before hand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "params = {'eta': 0.02, 'max_depth': 4, 'subsample': 0.9, 'colsample_bytree': 0.9, \n",
    "          'objective': 'binary:logistic', 'eval_metric': 'auc', 'silent': True}\n",
    "\n",
    "\n",
    "#xgb = XGBClassifier()\n",
    "#xgb.set_params(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Generate data for stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "C4S = Clf4Stack_xgb(xgb, \n",
    "                    gini_coefficient, \n",
    "                    nrounds=2000,\n",
    "                    early_stopping_rounds=100, \n",
    "                    test_size=0.25, \n",
    "                    verbose=100, \n",
    "                    n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Round 1/5=====\n",
      "[0]\ttrain-gini:-0.191351\tvalid-gini:-0.171783\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 100 rounds.\n",
      "[100]\ttrain-gini:-0.250998\tvalid-gini:-0.237442\n",
      "Stopping. Best iteration:\n",
      "[0]\ttrain-gini:-0.191351\tvalid-gini:-0.171783\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'xgboost' has no attribute 'predict_proba'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-9985553154eb>\u001b[0m in \u001b[0;36mfit_predict\u001b[1;34m(self, trainX, trainy, testX)\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[1;31m# ntree_limit=xgb_model.best_ntree_limit+50) / (2*kfold)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m             \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mntree_limit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_ntree_limit\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain4stack\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest4stack\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mntree_limit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_ntree_limit\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'xgboost' has no attribute 'predict_proba'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "C4S.fit_predict(trainX, trainy, testX)\n",
    "\n",
    "C4S.output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
